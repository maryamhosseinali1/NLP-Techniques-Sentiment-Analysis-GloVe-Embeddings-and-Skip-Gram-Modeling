{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VngyxOXVZVVR",
        "outputId": "86be23b3-1f50-4c58-eb3b-4ffa9a6299a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = '/content/drive/My Drive/training.1600000.processed.noemoticon.csv'\n"
      ],
      "metadata": {
        "id": "v7YsvPo9ZlEX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JANg1KMaZJi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "csv_file_path = '/content/drive/My Drive/training.1600000.processed.noemoticon.csv'\n",
        "\n",
        "# loading dataset\n",
        "data = pd.read_csv(csv_file_path, encoding='ISO-8859-1', names=['target', 'ids', 'date', 'flag', 'user', 'text'])\n",
        "\n",
        "data.sample(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mXLqpGFuaNec",
        "outputId": "524e0b44-2fc0-4777-d905-8df930e672b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target         ids                          date      flag  \\\n",
              "77071         0  1695996663  Mon May 04 07:23:49 PDT 2009  NO_QUERY   \n",
              "1540578       4  2180499737  Mon Jun 15 10:33:17 PDT 2009  NO_QUERY   \n",
              "371074        0  2050325219  Fri Jun 05 18:28:10 PDT 2009  NO_QUERY   \n",
              "1497847       4  2070465910  Sun Jun 07 17:44:44 PDT 2009  NO_QUERY   \n",
              "1362356       4  2049304316  Fri Jun 05 16:38:54 PDT 2009  NO_QUERY   \n",
              "\n",
              "                    user                                               text  \n",
              "77071      xSummerLovinx                    has to go back to KS tomorrow.   \n",
              "1540578     omgxitssarah  @ddlovato, this is gonna b a very energetic sh...  \n",
              "371074   mariana_pereira  @tommcfly LOL you did it a lot in Brazil didn'...  \n",
              "1497847       CraigFaulk      @MariaHo Go Maria! Go Lakers! You can do it!   \n",
              "1362356          mwinkle  @mkennedy cool, it's just mwinkle at you can g...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efea568b-961e-4eb8-a038-ea8bc430bb43\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77071</th>\n",
              "      <td>0</td>\n",
              "      <td>1695996663</td>\n",
              "      <td>Mon May 04 07:23:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>xSummerLovinx</td>\n",
              "      <td>has to go back to KS tomorrow.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1540578</th>\n",
              "      <td>4</td>\n",
              "      <td>2180499737</td>\n",
              "      <td>Mon Jun 15 10:33:17 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>omgxitssarah</td>\n",
              "      <td>@ddlovato, this is gonna b a very energetic sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371074</th>\n",
              "      <td>0</td>\n",
              "      <td>2050325219</td>\n",
              "      <td>Fri Jun 05 18:28:10 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mariana_pereira</td>\n",
              "      <td>@tommcfly LOL you did it a lot in Brazil didn'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497847</th>\n",
              "      <td>4</td>\n",
              "      <td>2070465910</td>\n",
              "      <td>Sun Jun 07 17:44:44 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>CraigFaulk</td>\n",
              "      <td>@MariaHo Go Maria! Go Lakers! You can do it!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1362356</th>\n",
              "      <td>4</td>\n",
              "      <td>2049304316</td>\n",
              "      <td>Fri Jun 05 16:38:54 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mwinkle</td>\n",
              "      <td>@mkennedy cool, it's just mwinkle at you can g...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efea568b-961e-4eb8-a038-ea8bc430bb43')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-efea568b-961e-4eb8-a038-ea8bc430bb43 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-efea568b-961e-4eb8-a038-ea8bc430bb43');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96b959b5-5dfb-4018-9af8-094e5a7e57e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96b959b5-5dfb-4018-9af8-094e5a7e57e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96b959b5-5dfb-4018-9af8-094e5a7e57e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **part1**"
      ],
      "metadata": {
        "id": "2wN603WVxjuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choosing 5000 negative and 5000 positive tweets randomly\n",
        "\n",
        "negative_samples = data[data['target'] == 0].sample(n=5000)\n",
        "positive_samples = data[data['target'] == 4].sample(n=5000)\n",
        "\n",
        "# concat negative and positive samples into sampled_data\n",
        "sampled_data = pd.concat([negative_samples, positive_samples]).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "1mpOL3RyakJO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A22uZsjZa_T-",
        "outputId": "d762af02-f86e-4534-e739-a9788f1ec209"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vok6rK5BP798"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "\t# converting text to lowercase\n",
        "\ttext = text.lower()\n",
        "\n",
        "\t# removing URLs\n",
        "\ttext = re.sub(r'http\\S+|www.\\S+', '', text)\n",
        "\n",
        "\t# removing punctuation\n",
        "\ttranslator = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "\ttext = text.translate(translator)\n",
        "\n",
        "\t# tokenization\n",
        "\twords = word_tokenize(text)\n",
        "\n",
        "\t# removing stopwords\n",
        "\tfiltered_words = [word for word in words if word not in stopwords.words('english')]\n",
        "\n",
        "\t# stemming\n",
        "\tstemmer = PorterStemmer()\n",
        "\tstemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "\n",
        "\t# rejoin words to form the processed text\n",
        "\treturn ' '.join(stemmed_words)\n"
      ],
      "metadata": {
        "id": "AA1TQhehbXnN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_data['processed_text'] = sampled_data['text'].apply(preprocess_text)\n",
        "\n",
        "print(sampled_data[['text', 'processed_text']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG9ERrAscGae",
        "outputId": "3966fb6c-9792-4e49-ec4a-fdbf169db695"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  Watching the premier of Kendra, making study n...   \n",
            "1                               Weekend almost done    \n",
            "2  Defeated  ive been reading all my required rea...   \n",
            "3                                  has a headache..    \n",
            "4  Is killing it again today! My feet kill though...   \n",
            "\n",
            "                                      processed_text  \n",
            "0  watch premier kendra make studi notecard go be...  \n",
            "1                                weekend almost done  \n",
            "2  defeat ive read requir read cant seem rememb a...  \n",
            "3                                            headach  \n",
            "4  kill today feet kill though post work pint ton...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# splitting the dataset\n",
        "X = sampled_data['text']  # features\n",
        "y = sampled_data['target']  # labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "8AkB9CIHcbkV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **part2**"
      ],
      "metadata": {
        "id": "0CwbVydsaHGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# converting the processed_text column to a list of documents\n",
        "documents = sampled_data['processed_text'].tolist()\n",
        "\n",
        "# creating a sorted list of unique words in the documents to form the vocabulary\n",
        "vocabulary = sorted(set(word for document in documents for word in document.split()))\n",
        "\n",
        "# an empty list for binary TF vectors\n",
        "binary_tf_matrix = []\n",
        "\n",
        " # binary TF matrix\n",
        "for document in documents:\n",
        "\n",
        "    # a set of unique words in the current document\n",
        "    words_in_document = set(document.split())\n",
        "\n",
        "    # setting the binary TF vector with zeros\n",
        "    binary_tf_vector = [0] * len(vocabulary)\n",
        "\n",
        "    # iterating over vocab and when a word is present in the document,\n",
        "    # setting the corresponding value to 1\n",
        "    for index, word in enumerate(vocabulary):\n",
        "        if word in words_in_document:\n",
        "            binary_tf_vector[index] = 1\n",
        "\n",
        "\n",
        "    binary_tf_matrix.append(binary_tf_vector)\n",
        "\n",
        "# converting the binary TF matrix to a DataFrame\n",
        "binary_tf_df = pd.DataFrame(binary_tf_matrix, columns=vocabulary)\n",
        "\n"
      ],
      "metadata": {
        "id": "HUReBuNydwHQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9quMMYOfae8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**part** **5** **for** **Term** **Frequency**"
      ],
      "metadata": {
        "id": "EM1IkLixsIjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LE_tkGJ2aRN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# re-defining vocabulary\n",
        "vocabulary = sorted(set(word for document in sampled_data['processed_text'].tolist() for word in document.split()))\n",
        "\n",
        "# if 'binary_tf_df' has not been created , recreate it here\n",
        "binary_tf_matrix = []\n",
        "\n",
        "for document in sampled_data['processed_text'].tolist():\n",
        "    words_in_document = set(document.split())\n",
        "    binary_tf_vector = [1 if word in words_in_document else 0 for word in vocabulary]\n",
        "    binary_tf_matrix.append(binary_tf_vector)\n",
        "\n",
        "binary_tf_df = pd.DataFrame(binary_tf_matrix, columns=vocabulary)\n",
        "\n",
        "# align 'binary_tf_df' with labels 'y'\n",
        "X = binary_tf_df.values\n",
        "y = sampled_data['target']  # Ensure label column\n",
        "\n",
        "# splitting the dataset into training and testing sets\n",
        "X_train_tf, X_test_tf, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# initialize and train the Naive Bayes classifier\n",
        "clf_tf = MultinomialNB()\n",
        "clf_tf.fit(X_train_tf, y_train)\n",
        "\n",
        "# predict on the test set and evaluate\n",
        "y_pred_tf = clf_tf.predict(X_test_tf)\n",
        "\n",
        "# as'4' is the label for the positive class\n",
        "print(\"Performance with TF Embedding:\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_tf, pos_label=4)}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_tf, pos_label=4)}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_tf, pos_label=4)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vL01SHweVIc",
        "outputId": "7c811fa6-752c-416b-95b9-4954b496b3ef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance with TF Embedding:\n",
            "F1-score: 0.7059447983014863\n",
            "Precision: 0.7421875\n",
            "Recall: 0.6730769230769231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **part3**"
      ],
      "metadata": {
        "id": "GZyBvPbqbvO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "documents = sampled_data['processed_text'].tolist()\n",
        "\n",
        "# function to calculate TF\n",
        "def compute_tf(document):\n",
        "    tf_dict = defaultdict(int)\n",
        "    words = document.split()\n",
        "    for word in words:\n",
        "        tf_dict[word] += 1\n",
        "    total_terms = len(words)\n",
        "    for word, count in tf_dict.items():\n",
        "        tf_dict[word] = count / total_terms\n",
        "    return tf_dict\n",
        "\n",
        "# Function to calculate IDF\n",
        "def compute_idf(documents):\n",
        "    idf_dict = defaultdict(int)\n",
        "    N = len(documents)\n",
        "    for document in documents:\n",
        "        for word in set(document.split()):  # unique words\n",
        "            idf_dict[word] += 1\n",
        "    for word, count in idf_dict.items():\n",
        "        idf_dict[word] = math.log(N / count)\n",
        "    return idf_dict\n",
        "\n",
        "# Function to calculate TF-IDF\n",
        "def compute_tfidf(documents):\n",
        "    idfs = compute_idf(documents)\n",
        "    tfidf_matrix = []\n",
        "\n",
        "    for document in documents:\n",
        "        tf_dict = compute_tf(document)\n",
        "        tfidf_vector = {word: tf * idfs[word] for word, tf in tf_dict.items()}\n",
        "        tfidf_matrix.append(tfidf_vector)\n",
        "\n",
        "    return tfidf_matrix\n",
        "# computing the TF-IDF matrix\n",
        "tfidf_matrix = compute_tfidf(documents)\n",
        "\n",
        "# convert matrix into a dense matrix\n",
        "# creating a sorted list of unique words in the documents to form the vocabulary\n",
        "vocabulary = sorted(set(word for document in documents for word in document.split()))\n",
        "\n",
        "# create a mapping of vocabulary words to their indexes\n",
        "vocab_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "\n",
        "# a matrix to store the TF-IDF vectors\n",
        "dense_tfidf_matrix = []\n",
        "for doc_vector in tfidf_matrix:\n",
        "\n",
        "    doc_tfidf_vector = [0] * len(vocabulary)\n",
        "    for word, tfidf_value in doc_vector.items():\n",
        "        index = vocab_index[word]\n",
        "        doc_tfidf_vector[index] = tfidf_value\n",
        "    dense_tfidf_matrix.append(doc_tfidf_vector)\n",
        "\n",
        "# Convert the dense TF-IDF matrix to a DataFrame\n",
        "tfidf_df = pd.DataFrame(dense_tfidf_matrix, columns=vocabulary)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CwIhBYuwYCzM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**part** **5** **for** **TF-IDF**"
      ],
      "metadata": {
        "id": "Hu6RCVGyq-X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "\n",
        "# align 'tfidf_df' with labels 'y'\n",
        "X = tfidf_df.values\n",
        "y = sampled_data['target']  # Ensure this is your label column\n",
        "\n",
        "# pslitting the dataset into training and testing sets\n",
        "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# initialize and train the Naive Bayes classifier with TF-IDF vectors\n",
        "clf_tfidf = MultinomialNB()\n",
        "clf_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the test set and evaluate\n",
        "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "# as the label positive class is '4'\n",
        "print(\"Performance with TF-IDF Embedding:\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_tfidf, pos_label=4)}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_tfidf, pos_label=4)}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_tfidf, pos_label=4)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coGP99JvZw_T",
        "outputId": "f40952bc-acf3-4b69-8532-81490a0b493a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance with TF-IDF Embedding:\n",
            "F1-score: 0.6859903381642511\n",
            "Precision: 0.7302857142857143\n",
            "Recall: 0.6467611336032388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **part4**"
      ],
      "metadata": {
        "id": "ioooF9lCxTJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PKrXo2i4e1Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "documents = sampled_data['processed_text'].tolist()\n",
        "\n",
        "# a function to compute PPMI\n",
        "def compute_ppmi(documents):\n",
        "    word_counts = Counter() #frequency of each word\n",
        "    co_occurrences = defaultdict(Counter) # how often pairs of words co-occur\n",
        "    total_co_occurrences = 0 #count of all word pairs\n",
        "\n",
        "    # calculate word frequencies and co-occurs\n",
        "    for document in documents:\n",
        "        words = document.split()\n",
        "        for i, word in enumerate(words):\n",
        "            word_counts[word] += 1\n",
        "            for j in range(max(0, i - 5), min(i + 5 + 1, len(words))):\n",
        "                if i != j:\n",
        "                    co_occurrences[word][words[j]] += 1\n",
        "                    total_co_occurrences += 1\n",
        "\n",
        "    # compute PPMI\n",
        "    ppmi_matrix = defaultdict(dict)\n",
        "    for word, contexts in co_occurrences.items():\n",
        "        for context_word, co_occurrence in contexts.items():\n",
        "            pmi = math.log2((co_occurrence / total_co_occurrences) / ((word_counts[word] / len(word_counts)) * (word_counts[context_word] / len(word_counts))))\n",
        "            ppmi = max(pmi, 0)\n",
        "            ppmi_matrix[word][context_word] = ppmi\n",
        "\n",
        "    return ppmi_matrix, word_counts, co_occurrences\n",
        "\n",
        "ppmi_matrix, word_counts, co_occurrences = compute_ppmi(documents)\n"
      ],
      "metadata": {
        "id": "wlJRUKLlC-EN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a sorted list of unique words\n",
        "vocabulary = sorted(word_counts.keys())\n",
        "vocab_index = {word: i for i, word in enumerate(vocabulary)}\n",
        "\n",
        "\n",
        "dense_ppmi_matrix = np.zeros((len(documents), len(vocabulary)))\n",
        "# fill matrix with PPMI values\n",
        "for i, document in enumerate(documents):\n",
        "    words = document.split()\n",
        "    for word in words:\n",
        "        if word in vocab_index:  # only consider words in the vocabulary\n",
        "            for context_word, ppmi_value in ppmi_matrix[word].items():\n",
        "                if context_word in vocab_index:\n",
        "                    j = vocab_index[context_word]\n",
        "                    dense_ppmi_matrix[i, j] = max(dense_ppmi_matrix[i, j], ppmi_value)  # use the max PPMI value\n",
        "\n",
        "# converting the dense PPMI matrix to a DataFrame\n",
        "ppmi_df = pd.DataFrame(dense_ppmi_matrix, columns=vocabulary)\n"
      ],
      "metadata": {
        "id": "knBpgGKnGOm2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**part** **5** **for** **PPMI**"
      ],
      "metadata": {
        "id": "NUIA--wSxNNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_ppmi = ppmi_df.values\n",
        "y = sampled_data['target'].values  # ensure label column\n",
        "\n",
        "# splitting the dataset into training and testing sets\n",
        "X_train_ppmi, X_test_ppmi, y_train, y_test = train_test_split(X_ppmi, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# initialize and train the Naive Bayes classifier with PPMI vectors\n",
        "clf_ppmi = MultinomialNB()\n",
        "clf_ppmi.fit(X_train_ppmi, y_train)\n",
        "\n",
        "# predict on the test set and evaluate\n",
        "y_pred_ppmi = clf_ppmi.predict(X_test_ppmi)\n",
        "# # as the label positive class is '4'\n",
        "print(\"Performance with PPMI Embedding:\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_ppmi, pos_label=4)}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_ppmi, pos_label=4)}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_ppmi, pos_label=4)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox33FLnPGlh0",
        "outputId": "8eb34970-48f0-4810-e189-880ffdcba25d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance with PPMI Embedding:\n",
            "F1-score: 0.6877265665458312\n",
            "Precision: 0.704135737009544\n",
            "Recall: 0.6720647773279352\n"
          ]
        }
      ]
    }
  ]
}